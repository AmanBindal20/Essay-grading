{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>wordnetscore</th>\n",
       "      <th>correctN</th>\n",
       "      <th>misspeltN</th>\n",
       "      <th>nounsN</th>\n",
       "      <th>verbsN</th>\n",
       "      <th>adverbsN</th>\n",
       "      <th>adjectivesN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14834</th>\n",
       "      <td>123</td>\n",
       "      <td>1.37</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>94.308943</td>\n",
       "      <td>4.878049</td>\n",
       "      <td>22.764228</td>\n",
       "      <td>6.504065</td>\n",
       "      <td>6.504065</td>\n",
       "      <td>8.130081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>180</td>\n",
       "      <td>1.55</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>93.888889</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>22.777778</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>7.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>169</td>\n",
       "      <td>1.62</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>96.449704</td>\n",
       "      <td>1.775148</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>5.917160</td>\n",
       "      <td>5.917160</td>\n",
       "      <td>5.325444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14837</th>\n",
       "      <td>199</td>\n",
       "      <td>1.69</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>87.939698</td>\n",
       "      <td>9.045226</td>\n",
       "      <td>17.587940</td>\n",
       "      <td>3.517588</td>\n",
       "      <td>3.517588</td>\n",
       "      <td>2.010050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14838</th>\n",
       "      <td>162</td>\n",
       "      <td>1.74</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>97.530864</td>\n",
       "      <td>2.469136</td>\n",
       "      <td>21.604938</td>\n",
       "      <td>4.938272</td>\n",
       "      <td>4.938272</td>\n",
       "      <td>9.259259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          length  lexical_diversity  n_sentences  wordnetscore   correctN  \\\n",
       "essay_id                                                                    \n",
       "14834        123               1.37            9             3  94.308943   \n",
       "14835        180               1.55           10             6  93.888889   \n",
       "14836        169               1.62            9            24  96.449704   \n",
       "14837        199               1.69           11             4  87.939698   \n",
       "14838        162               1.74           11             8  97.530864   \n",
       "\n",
       "          misspeltN     nounsN    verbsN  adverbsN  adjectivesN  \n",
       "essay_id                                                         \n",
       "14834      4.878049  22.764228  6.504065  6.504065     8.130081  \n",
       "14835      6.111111  22.777778  6.666667  6.666667     7.777778  \n",
       "14836      1.775148  23.076923  5.917160  5.917160     5.325444  \n",
       "14837      9.045226  17.587940  3.517588  3.517588     2.010050  \n",
       "14838      2.469136  21.604938  4.938272  4.938272     9.259259  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "essays = pd.read_csv('trained.csv')\n",
    "essays.set_index('essay_id',inplace=True, drop=True)\n",
    "\n",
    "def newCols(essays):\n",
    "    correctNew = []\n",
    "    misspeltNew = []\n",
    "    nounsNew = []\n",
    "    verbsNew = []\n",
    "    adverbsNew = []\n",
    "    adjectivesNew = []\n",
    "    for index,essay in essays.iterrows():\n",
    "        correctNew.append(essay.correct/essay.length*100)\n",
    "        misspeltNew.append(essay.misspelt/essay.length*100)\n",
    "        nounsNew.append(essay.nouns/essay.length*100)\n",
    "        verbsNew.append(essay.adverbs/essay.length*100)\n",
    "        adverbsNew.append(essay.adverbs/essay.length*100)\n",
    "        adjectivesNew.append(essay.adjectives/essay.length*100)\n",
    "    essays = essays.assign(correctN = correctNew)\n",
    "    essays = essays.assign(misspeltN = misspeltNew)\n",
    "    essays = essays.assign(nounsN = nounsNew)\n",
    "    essays = essays.assign(verbsN = verbsNew)\n",
    "    essays = essays.assign(adverbsN = adverbsNew)\n",
    "    essays = essays.assign(adjectivesN = adjectivesNew)\n",
    "    return essays\n",
    "essays = newCols(essays)\n",
    "essays.head()\n",
    "X = essays.drop(['domain1_score','essay','essay_set','normal_score','misspelt','correct','nouns','verbs','adverbs','adjectives'], axis=1)\n",
    "y = essays['normal_score']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>wordnetscore</th>\n",
       "      <th>correctN</th>\n",
       "      <th>misspeltN</th>\n",
       "      <th>nounsN</th>\n",
       "      <th>verbsN</th>\n",
       "      <th>adverbsN</th>\n",
       "      <th>adjectivesN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14834</th>\n",
       "      <td>-0.564170</td>\n",
       "      <td>-1.139380</td>\n",
       "      <td>0.043467</td>\n",
       "      <td>-1.033892</td>\n",
       "      <td>0.507557</td>\n",
       "      <td>-0.498194</td>\n",
       "      <td>0.140759</td>\n",
       "      <td>0.499554</td>\n",
       "      <td>0.499554</td>\n",
       "      <td>0.732825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>0.447114</td>\n",
       "      <td>-0.200283</td>\n",
       "      <td>0.332181</td>\n",
       "      <td>0.012597</td>\n",
       "      <td>0.397134</td>\n",
       "      <td>-0.155581</td>\n",
       "      <td>0.144711</td>\n",
       "      <td>0.574577</td>\n",
       "      <td>0.574577</td>\n",
       "      <td>0.580263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>0.251954</td>\n",
       "      <td>0.164922</td>\n",
       "      <td>0.043467</td>\n",
       "      <td>6.291528</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>-1.360350</td>\n",
       "      <td>0.231964</td>\n",
       "      <td>0.228764</td>\n",
       "      <td>0.228764</td>\n",
       "      <td>-0.481705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14837</th>\n",
       "      <td>0.784208</td>\n",
       "      <td>0.530126</td>\n",
       "      <td>0.620895</td>\n",
       "      <td>-0.685062</td>\n",
       "      <td>-1.166780</td>\n",
       "      <td>0.659678</td>\n",
       "      <td>-1.369028</td>\n",
       "      <td>-0.878365</td>\n",
       "      <td>-0.878365</td>\n",
       "      <td>-1.917415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14838</th>\n",
       "      <td>0.127761</td>\n",
       "      <td>0.790986</td>\n",
       "      <td>0.620895</td>\n",
       "      <td>0.710256</td>\n",
       "      <td>1.354531</td>\n",
       "      <td>-1.167522</td>\n",
       "      <td>-0.197375</td>\n",
       "      <td>-0.222881</td>\n",
       "      <td>-0.222881</td>\n",
       "      <td>1.221809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length  lexical_diversity  n_sentences  wordnetscore  correctN  \\\n",
       "essay_id                                                                     \n",
       "14834    -0.564170          -1.139380     0.043467     -1.033892  0.507557   \n",
       "14835     0.447114          -0.200283     0.332181      0.012597  0.397134   \n",
       "14836     0.251954           0.164922     0.043467      6.291528  1.070317   \n",
       "14837     0.784208           0.530126     0.620895     -0.685062 -1.166780   \n",
       "14838     0.127761           0.790986     0.620895      0.710256  1.354531   \n",
       "\n",
       "          misspeltN    nounsN    verbsN  adverbsN  adjectivesN  \n",
       "essay_id                                                        \n",
       "14834     -0.498194  0.140759  0.499554  0.499554     0.732825  \n",
       "14835     -0.155581  0.144711  0.574577  0.574577     0.580263  \n",
       "14836     -1.360350  0.231964  0.228764  0.228764    -0.481705  \n",
       "14837      0.659678 -1.369028 -0.878365 -0.878365    -1.917415  \n",
       "14838     -1.167522 -0.197375 -0.222881 -0.222881     1.221809  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X=(X-X.min())/(X.max()-X.min())\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "col_to_std = ['length','lexical_diversity','n_sentences','wordnetscore','correctN','misspeltN','nounsN','verbsN','adverbsN','adjectivesN']\n",
    "X[col_to_std] = StandardScaler().fit_transform(X[col_to_std])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>wordnetscore</th>\n",
       "      <th>correctN</th>\n",
       "      <th>misspeltN</th>\n",
       "      <th>nounsN</th>\n",
       "      <th>verbsN</th>\n",
       "      <th>adverbsN</th>\n",
       "      <th>adjectivesN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704630</td>\n",
       "      <td>0.784995</td>\n",
       "      <td>0.600038</td>\n",
       "      <td>-0.116262</td>\n",
       "      <td>0.108707</td>\n",
       "      <td>0.022393</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.044306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lexical_diversity</th>\n",
       "      <td>0.704630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505644</td>\n",
       "      <td>0.394189</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>-0.057293</td>\n",
       "      <td>0.044152</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>-0.219457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_sentences</th>\n",
       "      <td>0.784995</td>\n",
       "      <td>0.505644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.466756</td>\n",
       "      <td>-0.167746</td>\n",
       "      <td>0.163243</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.090742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordnetscore</th>\n",
       "      <td>0.600038</td>\n",
       "      <td>0.394189</td>\n",
       "      <td>0.466756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037196</td>\n",
       "      <td>-0.025936</td>\n",
       "      <td>0.021304</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.056399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctN</th>\n",
       "      <td>-0.116262</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>-0.167746</td>\n",
       "      <td>0.037196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.955984</td>\n",
       "      <td>-0.045721</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>-0.075020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misspeltN</th>\n",
       "      <td>0.108707</td>\n",
       "      <td>-0.057293</td>\n",
       "      <td>0.163243</td>\n",
       "      <td>-0.025936</td>\n",
       "      <td>-0.955984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>0.105793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nounsN</th>\n",
       "      <td>0.022393</td>\n",
       "      <td>0.044152</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.021304</td>\n",
       "      <td>-0.045721</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.303579</td>\n",
       "      <td>-0.303579</td>\n",
       "      <td>-0.095574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbsN</th>\n",
       "      <td>0.048700</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>-0.303579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.228514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adverbsN</th>\n",
       "      <td>0.048700</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>-0.303579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.228514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjectivesN</th>\n",
       "      <td>0.044306</td>\n",
       "      <td>-0.219457</td>\n",
       "      <td>0.090742</td>\n",
       "      <td>0.056399</td>\n",
       "      <td>-0.075020</td>\n",
       "      <td>0.105793</td>\n",
       "      <td>-0.095574</td>\n",
       "      <td>0.228514</td>\n",
       "      <td>0.228514</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     length  lexical_diversity  n_sentences  wordnetscore  \\\n",
       "length             1.000000           0.704630     0.784995      0.600038   \n",
       "lexical_diversity  0.704630           1.000000     0.505644      0.394189   \n",
       "n_sentences        0.784995           0.505644     1.000000      0.466756   \n",
       "wordnetscore       0.600038           0.394189     0.466756      1.000000   \n",
       "correctN          -0.116262           0.044281    -0.167746      0.037196   \n",
       "misspeltN          0.108707          -0.057293     0.163243     -0.025936   \n",
       "nounsN             0.022393           0.044152     0.003968      0.021304   \n",
       "verbsN             0.048700          -0.190167     0.095274      0.132317   \n",
       "adverbsN           0.048700          -0.190167     0.095274      0.132317   \n",
       "adjectivesN        0.044306          -0.219457     0.090742      0.056399   \n",
       "\n",
       "                   correctN  misspeltN    nounsN    verbsN  adverbsN  \\\n",
       "length            -0.116262   0.108707  0.022393  0.048700  0.048700   \n",
       "lexical_diversity  0.044281  -0.057293  0.044152 -0.190167 -0.190167   \n",
       "n_sentences       -0.167746   0.163243  0.003968  0.095274  0.095274   \n",
       "wordnetscore       0.037196  -0.025936  0.021304  0.132317  0.132317   \n",
       "correctN           1.000000  -0.955984 -0.045721  0.016804  0.016804   \n",
       "misspeltN         -0.955984   1.000000  0.031232  0.019553  0.019553   \n",
       "nounsN            -0.045721   0.031232  1.000000 -0.303579 -0.303579   \n",
       "verbsN             0.016804   0.019553 -0.303579  1.000000  1.000000   \n",
       "adverbsN           0.016804   0.019553 -0.303579  1.000000  1.000000   \n",
       "adjectivesN       -0.075020   0.105793 -0.095574  0.228514  0.228514   \n",
       "\n",
       "                   adjectivesN  \n",
       "length                0.044306  \n",
       "lexical_diversity    -0.219457  \n",
       "n_sentences           0.090742  \n",
       "wordnetscore          0.056399  \n",
       "correctN             -0.075020  \n",
       "misspeltN             0.105793  \n",
       "nounsN               -0.095574  \n",
       "verbsN                0.228514  \n",
       "adverbsN              0.228514  \n",
       "adjectivesN           1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split X and y into X_\n",
    "n_X_train, n_X_test, n_y_train, n_y_test = train_test_split(normalized_X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(n_X_train, n_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.69293551, -0.40793348,  0.44695263,  2.51322157,  3.3054924 ,\n",
       "        2.57487967,  1.58292482,  0.34557344,  0.34557344,  1.23970997])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5541919471699364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,accuracy_score\n",
    "print(regression_model.score(n_X_test, n_y_test))\n",
    "y_pred = regression_model.predict(n_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(n_y_test,y_pred)\n",
    "plt.xlabel('y-actual')\n",
    "plt.ylabel('y-predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse = {} 0.6479748302369932\n",
      "r2_score = {} 0.5541919471699365\n",
      "rmse = {} 0.622060032898186\n",
      "r2_score = {} 0.5891377558987688\n",
      "rmse = {} 0.7503098573068824\n",
      "r2_score = {} 0.4022591454730877\n",
      "rmse = {} 7.460254737946227\n",
      "r2_score = {} -58.09339618101234\n",
      "rmse = {} 206.14570218479375\n",
      "r2_score = {} -45120.15474842138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "for val in range(1,6):\n",
    "    poly_reg = PolynomialFeatures(degree=val)\n",
    "    X_poly = poly_reg.fit_transform(n_X_train)\n",
    "    pol_reg = LinearRegression()\n",
    "    pol_reg.fit(X_poly, n_y_train)\n",
    "    y_predict = pol_reg.predict(poly_reg.transform(n_X_test))\n",
    "    print(\"rmse = {}\",math.sqrt(mean_squared_error(y_predict, n_y_test)))\n",
    "    print(\"r2_score = {}\",r2_score(n_y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split X and y into X_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7276764202821226"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.45249701, -0.05392417,  0.07036734,  0.30019698,  0.28291999,\n",
       "        0.24711972,  0.11554341,  0.04244274,  0.04244274,  0.0858835 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5495279120543642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,accuracy_score\n",
    "print(regression_model.score(X_test, y_test))\n",
    "y_pred = regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6479748302369933"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_predict = regression_model.predict(X_test)\n",
    "\n",
    "regression_model_mse = mean_squared_error(y_predict, y_test)\n",
    "\n",
    "regression_model_mse\n",
    "import math\n",
    "\n",
    "math.sqrt(regression_model_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse = {} 0.6306914822024646\n",
      "r2_score = {} 0.5775576192409284\n",
      "rmse = {} 0.5916091127038631\n",
      "r2_score = {} 0.6282908429967584\n",
      "rmse = {} 0.5599185349430765\n",
      "r2_score = {} 0.6670467653220038\n",
      "rmse = {} 0.45790600811189314\n",
      "r2_score = {} 0.7773174253770506\n",
      "rmse = {} 0.07276465032099905\n",
      "r2_score = {} 0.994376917654697\n",
      "rmse = {} 0.005536705011815039\n",
      "r2_score = {} 0.9999674436040911\n",
      "rmse = {} 0.01099655740002152\n",
      "r2_score = {} 0.9998715757490952\n",
      "rmse = {} 0.010830575662900015\n",
      "r2_score = {} 0.9998754233547262\n",
      "rmse = {} 0.019829554872429184\n",
      "r2_score = {} 0.9995824009702223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "for val in range(1,10):\n",
    "    poly_reg = PolynomialFeatures(degree=val)\n",
    "    X_poly = poly_reg.fit_transform(X)\n",
    "    pol_reg = LinearRegression()\n",
    "    pol_reg.fit(X_poly, y)\n",
    "    y_predict = pol_reg.predict(X_poly)\n",
    "    print(\"rmse = {}\",math.sqrt(mean_squared_error(y_predict, y)))\n",
    "    print(\"r2_score = {}\",r2_score(y,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse = {} 0.6479748302369933\n",
      "r2_score = {} 0.5541919471699362\n",
      "rmse = {} 0.6213099581088788\n",
      "r2_score = {} 0.5901279870533731\n",
      "rmse = {} 0.750309857306848\n",
      "r2_score = {} 0.4022591454731427\n",
      "rmse = {} 7.5425161643890295\n",
      "r2_score = {} -59.403782497731\n",
      "rmse = {} 274.90072371708584\n",
      "r2_score = {} -80237.61104262668\n",
      "rmse = {} 2313.5611316403106\n",
      "r2_score = {} -5683207.571479998\n",
      "rmse = {} 2853.959339945022\n",
      "r2_score = {} -8648228.356563177\n",
      "rmse = {} 58674.84588876458\n",
      "r2_score = {} -3655405415.9515615\n",
      "rmse = {} 60677.866523718694\n",
      "r2_score = {} -3909239158.174019\n"
     ]
    }
   ],
   "source": [
    "for val in range(1,10):\n",
    "    poly_reg = PolynomialFeatures(degree=val)\n",
    "    X_poly = poly_reg.fit_transform(X_train)\n",
    "    pol_reg = LinearRegression()\n",
    "    pol_reg.fit(X_poly, y_train)\n",
    "    y_predict = pol_reg.predict(poly_reg.transform(X_test))\n",
    "    print(\"rmse = {}\",math.sqrt(mean_squared_error(y_predict, y_test)))\n",
    "    print(\"r2_score = {}\",r2_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>wordnetscore</th>\n",
       "      <th>correctN</th>\n",
       "      <th>misspeltN</th>\n",
       "      <th>nounsN</th>\n",
       "      <th>verbsN</th>\n",
       "      <th>adverbsN</th>\n",
       "      <th>adjectivesN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704630</td>\n",
       "      <td>0.784995</td>\n",
       "      <td>0.600038</td>\n",
       "      <td>-0.116262</td>\n",
       "      <td>0.108707</td>\n",
       "      <td>0.022393</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.044306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lexical_diversity</th>\n",
       "      <td>0.704630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505644</td>\n",
       "      <td>0.394189</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>-0.057293</td>\n",
       "      <td>0.044152</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>-0.219457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_sentences</th>\n",
       "      <td>0.784995</td>\n",
       "      <td>0.505644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.466756</td>\n",
       "      <td>-0.167746</td>\n",
       "      <td>0.163243</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.090742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordnetscore</th>\n",
       "      <td>0.600038</td>\n",
       "      <td>0.394189</td>\n",
       "      <td>0.466756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037196</td>\n",
       "      <td>-0.025936</td>\n",
       "      <td>0.021304</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.056399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctN</th>\n",
       "      <td>-0.116262</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>-0.167746</td>\n",
       "      <td>0.037196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.955984</td>\n",
       "      <td>-0.045721</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>-0.075020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misspeltN</th>\n",
       "      <td>0.108707</td>\n",
       "      <td>-0.057293</td>\n",
       "      <td>0.163243</td>\n",
       "      <td>-0.025936</td>\n",
       "      <td>-0.955984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>0.105793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nounsN</th>\n",
       "      <td>0.022393</td>\n",
       "      <td>0.044152</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.021304</td>\n",
       "      <td>-0.045721</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.303579</td>\n",
       "      <td>-0.303579</td>\n",
       "      <td>-0.095574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbsN</th>\n",
       "      <td>0.048700</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>-0.303579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.228514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adverbsN</th>\n",
       "      <td>0.048700</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>-0.303579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.228514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjectivesN</th>\n",
       "      <td>0.044306</td>\n",
       "      <td>-0.219457</td>\n",
       "      <td>0.090742</td>\n",
       "      <td>0.056399</td>\n",
       "      <td>-0.075020</td>\n",
       "      <td>0.105793</td>\n",
       "      <td>-0.095574</td>\n",
       "      <td>0.228514</td>\n",
       "      <td>0.228514</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     length  lexical_diversity  n_sentences  wordnetscore  \\\n",
       "length             1.000000           0.704630     0.784995      0.600038   \n",
       "lexical_diversity  0.704630           1.000000     0.505644      0.394189   \n",
       "n_sentences        0.784995           0.505644     1.000000      0.466756   \n",
       "wordnetscore       0.600038           0.394189     0.466756      1.000000   \n",
       "correctN          -0.116262           0.044281    -0.167746      0.037196   \n",
       "misspeltN          0.108707          -0.057293     0.163243     -0.025936   \n",
       "nounsN             0.022393           0.044152     0.003968      0.021304   \n",
       "verbsN             0.048700          -0.190167     0.095274      0.132317   \n",
       "adverbsN           0.048700          -0.190167     0.095274      0.132317   \n",
       "adjectivesN        0.044306          -0.219457     0.090742      0.056399   \n",
       "\n",
       "                   correctN  misspeltN    nounsN    verbsN  adverbsN  \\\n",
       "length            -0.116262   0.108707  0.022393  0.048700  0.048700   \n",
       "lexical_diversity  0.044281  -0.057293  0.044152 -0.190167 -0.190167   \n",
       "n_sentences       -0.167746   0.163243  0.003968  0.095274  0.095274   \n",
       "wordnetscore       0.037196  -0.025936  0.021304  0.132317  0.132317   \n",
       "correctN           1.000000  -0.955984 -0.045721  0.016804  0.016804   \n",
       "misspeltN         -0.955984   1.000000  0.031232  0.019553  0.019553   \n",
       "nounsN            -0.045721   0.031232  1.000000 -0.303579 -0.303579   \n",
       "verbsN             0.016804   0.019553 -0.303579  1.000000  1.000000   \n",
       "adverbsN           0.016804   0.019553 -0.303579  1.000000  1.000000   \n",
       "adjectivesN       -0.075020   0.105793 -0.095574  0.228514  0.228514   \n",
       "\n",
       "                   adjectivesN  \n",
       "length                0.044306  \n",
       "lexical_diversity    -0.219457  \n",
       "n_sentences           0.090742  \n",
       "wordnetscore          0.056399  \n",
       "correctN             -0.075020  \n",
       "misspeltN             0.105793  \n",
       "nounsN               -0.095574  \n",
       "verbsN                0.228514  \n",
       "adverbsN              0.228514  \n",
       "adjectivesN           1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
