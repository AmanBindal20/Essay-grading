{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "essays = pd.read_csv('AllFeaturesAllSets.csv')\n",
    "essays.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "X = essays.drop(['domain1_score','essay'], axis=1)\n",
    "y = essays[['domain1_score','essay_set']]\n",
    "y.iloc[0]['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(essay_set, score):\n",
    "        if essay_set == 1:\n",
    "            div = 12/3\n",
    "        elif essay_set == 2:\n",
    "            div = 5/3\n",
    "        elif essay_set == 3:\n",
    "            div = 3/3\n",
    "        elif essay_set == 4:\n",
    "            div = 3/3\n",
    "        elif essay_set == 5:\n",
    "            div = 4/3\n",
    "        elif essay_set == 6:\n",
    "            div = 4/3\n",
    "        elif essay_set == 7:\n",
    "            div = 25/3\n",
    "        elif essay_set == 8:\n",
    "            div = 50/3\n",
    "        return score/float(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   domain1_score  essay_set  score\n",
       "0              8          1   2.00\n",
       "1              9          1   2.25\n",
       "2              7          1   1.75\n",
       "3             10          1   2.50\n",
       "4              8          1   2.00"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = []\n",
    "for i in range(0,len(y)):\n",
    "    score = get_score(y.iloc[i]['essay_set'],y.iloc[i]['domain1_score'])\n",
    "    arr.append(score)\n",
    "\n",
    "y = y.assign(score=arr)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12257</th>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12258</th>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12259</th>\n",
       "      <td>2.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12260</th>\n",
       "      <td>2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12261</th>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "12257   1.44\n",
       "12258   1.92\n",
       "12259   2.28\n",
       "12260   2.64\n",
       "12261   1.80"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Xsets = [None] * 9\n",
    "ysets = [None] * 9\n",
    "for i in range(0,8):\n",
    "    Xsets[i] = X.loc[X['essay_set'] == i+1]\n",
    "    Xsets[i] = Xsets[i].drop(['essay_set'], axis=1)\n",
    "    ysets[i] = y.loc[y['essay_set'] == i+1]\n",
    "    ysets[i] = ysets[i].drop(['essay_set','domain1_score'], axis=1)\n",
    "\n",
    "ysets[6].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix,\n",
    "                             f1_score,\n",
    "                             make_scorer,\n",
    "                             SCORERS)\n",
    "def kappa(y_true, y_pred, weights=None, allow_off_by_one=False):\n",
    "    \"\"\"\n",
    "    Calculates the kappa inter-rater agreement between two the gold standard\n",
    "    and the predicted ratings. Potential values range from -1 (representing\n",
    "    complete disagreement) to 1 (representing complete agreement).  A kappa\n",
    "    value of 0 is expected if all agreement is due to chance.\n",
    "\n",
    "    In the course of calculating kappa, all items in ``y_true`` and ``y_pred`` will\n",
    "    first be converted to floats and then rounded to integers.\n",
    "\n",
    "    It is assumed that y_true and y_pred contain the complete range of possible\n",
    "    ratings.\n",
    "\n",
    "    This function contains a combination of code from yorchopolis's kappa-stats\n",
    "    and Ben Hamner's Metrics projects on Github.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like of float\n",
    "        The true/actual/gold labels for the data.\n",
    "    y_pred : array-like of float\n",
    "        The predicted/observed labels for the data.\n",
    "    weights : str or np.array, optional\n",
    "        Specifies the weight matrix for the calculation.\n",
    "        Options are ::\n",
    "\n",
    "            -  None = unweighted-kappa\n",
    "            -  'quadratic' = quadratic-weighted kappa\n",
    "            -  'linear' = linear-weighted kappa\n",
    "            -  two-dimensional numpy array = a custom matrix of\n",
    "\n",
    "        weights. Each weight corresponds to the\n",
    "        :math:`w_{ij}` values in the wikipedia description\n",
    "        of how to calculate weighted Cohen's kappa.\n",
    "        Defaults to None.\n",
    "    allow_off_by_one : bool, optional\n",
    "        If true, ratings that are off by one are counted as\n",
    "        equal, and all other differences are reduced by\n",
    "        one. For example, 1 and 2 will be considered to be\n",
    "        equal, whereas 1 and 3 will have a difference of 1\n",
    "        for when building the weights matrix.\n",
    "        Defaults to False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    k : float\n",
    "        The kappa score, or weighted kappa score.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    AssertionError\n",
    "        If ``y_true`` != ``y_pred``.\n",
    "    ValueError\n",
    "        If labels cannot be converted to int.\n",
    "    ValueError\n",
    "        If invalid weight scheme.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure that the lists are both the same length\n",
    "    assert(len(y_true) == len(y_pred))\n",
    "\n",
    "    # This rather crazy looking typecast is intended to work as follows:\n",
    "    # If an input is an int, the operations will have no effect.\n",
    "    # If it is a float, it will be rounded and then converted to an int\n",
    "    # because the ml_metrics package requires ints.\n",
    "    # If it is a str like \"1\", then it will be converted to a (rounded) int.\n",
    "    # If it is a str that can't be typecast, then the user is\n",
    "    # given a hopefully useful error message.\n",
    "    try:\n",
    "        y_true = [int(np.round(float(y))) for y in y_true]\n",
    "        y_pred = [int(np.round(float(y))) for y in y_pred]\n",
    "    except ValueError:\n",
    "        raise ValueError(\"For kappa, the labels should be integers or strings \"\n",
    "                         \"that can be converted to ints (E.g., '4.0' or '3').\")\n",
    "\n",
    "    # Figure out normalized expected values\n",
    "    min_rating = min(min(y_true), min(y_pred))\n",
    "    max_rating = max(max(y_true), max(y_pred))\n",
    "\n",
    "    # shift the values so that the lowest value is 0\n",
    "    # (to support scales that include negative values)\n",
    "    y_true = [y - min_rating for y in y_true]\n",
    "    y_pred = [y - min_rating for y in y_pred]\n",
    "\n",
    "    # Build the observed/confusion matrix\n",
    "    num_ratings = max_rating - min_rating + 1\n",
    "    observed = confusion_matrix(y_true, y_pred,\n",
    "                                labels=list(range(num_ratings)))\n",
    "    num_scored_items = float(len(y_true))\n",
    "\n",
    "    # Build weight array if weren't passed one\n",
    "    if isinstance(weights, str):\n",
    "        wt_scheme = weights\n",
    "        weights = None\n",
    "    else:\n",
    "        wt_scheme = ''\n",
    "    if weights is None:\n",
    "        weights = np.empty((num_ratings, num_ratings))\n",
    "        for i in range(num_ratings):\n",
    "            for j in range(num_ratings):\n",
    "                diff = abs(i - j)\n",
    "                if allow_off_by_one and diff:\n",
    "                    diff -= 1\n",
    "                if wt_scheme == 'linear':\n",
    "                    weights[i, j] = diff\n",
    "                elif wt_scheme == 'quadratic':\n",
    "                    weights[i, j] = diff ** 2\n",
    "                elif not wt_scheme:  # unweighted\n",
    "                    weights[i, j] = bool(diff)\n",
    "                else:\n",
    "                    raise ValueError('Invalid weight scheme specified for '\n",
    "                                     'kappa: {}'.format(wt_scheme))\n",
    "\n",
    "    hist_true = np.bincount(y_true, minlength=num_ratings)\n",
    "    hist_true = hist_true[: num_ratings] / num_scored_items\n",
    "    hist_pred = np.bincount(y_pred, minlength=num_ratings)\n",
    "    hist_pred = hist_pred[: num_ratings] / num_scored_items\n",
    "    expected = np.outer(hist_true, hist_pred)\n",
    "\n",
    "    # Normalize observed array\n",
    "    observed = observed / num_scored_items\n",
    "\n",
    "    # If all weights are zero, that means no disagreements matter.\n",
    "    k = 1.0\n",
    "    if np.count_nonzero(weights):\n",
    "        k -= (sum(sum(weights * observed)) / sum(sum(weights * expected)))\n",
    "\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa score for Set \n",
      "1\n",
      "0.8907563025210085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa score for Set \n",
      "2\n",
      "0.8972222222222223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa score for Set \n",
      "3\n",
      "0.6570605187319885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa score for Set \n",
      "4\n",
      "0.6112676056338028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa score for Set \n",
      "5\n",
      "0.7146814404432132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa score for Set \n",
      "6\n",
      "0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa score for Set \n",
      "7\n",
      "0.7006369426751592\n",
      "Kappa score for Set \n",
      "8\n",
      "0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# !pip install skll.metrics\n",
    "# import skll\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import (confusion_matrix,\n",
    "                             f1_score,\n",
    "                             make_scorer,\n",
    "                             SCORERS)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,8):\n",
    "    clf = svm.SVR(kernel = 'rbf')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xsets[i], ysets[i], test_size=0.2, random_state=1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #print(y_pred)\n",
    "    y_test=y_test.to_numpy(dtype=float, copy=False)\n",
    "    cappa_score = 0\n",
    "    \n",
    "    for j in range(0,len(y_test)):\n",
    "        #print(y_test[j],y_pred[j])\n",
    "        cappa_score+= kappa([y_test[j]],[y_pred[j]],weights='quadratic')\n",
    "#         print(kappa([y_test[j]],[y_pred[j]],weights='quadratic'))\n",
    "        \n",
    "    \n",
    "    avg_cappa_score = cappa_score/len(y_test)\n",
    "    print('Kappa score for Set ')\n",
    "    print(i+1)\n",
    "    print( avg_cappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.92853288 7.95074822 9.3371221  8.1455362  9.94057708]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "clf = svm.SVR(kernel = 'rbf')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xsets[0], ysets[0], test_size=0.2, random_state=1)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred[:5])\n",
    "cappa_score = 0\n",
    "#     for j in range(0,len(y_test)):\n",
    "#         cappa_score+= cohen_kappa_score([y_test[j]],[y_pred[j]],weights='quadratic')\n",
    "#     avg_cappa_score = cappa_score/len(y_test)\n",
    "#     print('Kappa score for Set '+i+1+' is '+avg_cappa_score+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
