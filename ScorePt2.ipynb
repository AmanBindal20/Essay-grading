{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>wordnetscore</th>\n",
       "      <th>correctN</th>\n",
       "      <th>misspeltN</th>\n",
       "      <th>nounsN</th>\n",
       "      <th>verbsN</th>\n",
       "      <th>adverbsN</th>\n",
       "      <th>adjectivesN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14834</th>\n",
       "      <td>123</td>\n",
       "      <td>1.37</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>94.308943</td>\n",
       "      <td>4.878049</td>\n",
       "      <td>22.764228</td>\n",
       "      <td>6.504065</td>\n",
       "      <td>6.504065</td>\n",
       "      <td>8.130081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>180</td>\n",
       "      <td>1.55</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>93.888889</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>22.777778</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>7.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>169</td>\n",
       "      <td>1.62</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>96.449704</td>\n",
       "      <td>1.775148</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>5.917160</td>\n",
       "      <td>5.917160</td>\n",
       "      <td>5.325444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14837</th>\n",
       "      <td>199</td>\n",
       "      <td>1.69</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>87.939698</td>\n",
       "      <td>9.045226</td>\n",
       "      <td>17.587940</td>\n",
       "      <td>3.517588</td>\n",
       "      <td>3.517588</td>\n",
       "      <td>2.010050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14838</th>\n",
       "      <td>162</td>\n",
       "      <td>1.74</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>97.530864</td>\n",
       "      <td>2.469136</td>\n",
       "      <td>21.604938</td>\n",
       "      <td>4.938272</td>\n",
       "      <td>4.938272</td>\n",
       "      <td>9.259259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          length  lexical_diversity  n_sentences  wordnetscore   correctN  \\\n",
       "essay_id                                                                    \n",
       "14834        123               1.37            9             3  94.308943   \n",
       "14835        180               1.55           10             6  93.888889   \n",
       "14836        169               1.62            9            24  96.449704   \n",
       "14837        199               1.69           11             4  87.939698   \n",
       "14838        162               1.74           11             8  97.530864   \n",
       "\n",
       "          misspeltN     nounsN    verbsN  adverbsN  adjectivesN  \n",
       "essay_id                                                         \n",
       "14834      4.878049  22.764228  6.504065  6.504065     8.130081  \n",
       "14835      6.111111  22.777778  6.666667  6.666667     7.777778  \n",
       "14836      1.775148  23.076923  5.917160  5.917160     5.325444  \n",
       "14837      9.045226  17.587940  3.517588  3.517588     2.010050  \n",
       "14838      2.469136  21.604938  4.938272  4.938272     9.259259  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "essays = pd.read_csv('trained.csv')\n",
    "essays.set_index('essay_id',inplace=True, drop=True)\n",
    "\n",
    "def newCols(essays):\n",
    "    correctNew = []\n",
    "    misspeltNew = []\n",
    "    nounsNew = []\n",
    "    verbsNew = []\n",
    "    adverbsNew = []\n",
    "    adjectivesNew = []\n",
    "    for index,essay in essays.iterrows():\n",
    "        correctNew.append(essay.correct/essay.length*100)\n",
    "        misspeltNew.append(essay.misspelt/essay.length*100)\n",
    "        nounsNew.append(essay.nouns/essay.length*100)\n",
    "        verbsNew.append(essay.adverbs/essay.length*100)\n",
    "        adverbsNew.append(essay.adverbs/essay.length*100)\n",
    "        adjectivesNew.append(essay.adjectives/essay.length*100)\n",
    "    essays = essays.assign(correctN = correctNew)\n",
    "    essays = essays.assign(misspeltN = misspeltNew)\n",
    "    essays = essays.assign(nounsN = nounsNew)\n",
    "    essays = essays.assign(verbsN = verbsNew)\n",
    "    essays = essays.assign(adverbsN = adverbsNew)\n",
    "    essays = essays.assign(adjectivesN = adjectivesNew)\n",
    "    return essays\n",
    "essays = newCols(essays)\n",
    "essays = essays.drop(['misspelt','correct','nouns','verbs','adverbs','adjectives'],axis=1)\n",
    "essays.to_csv(\"trainedPt2.csv\",index=False)\n",
    "X = essays.drop(['domain1_score','essay','essay_set','normal_score',], axis=1)\n",
    "y = essays['normal_score']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>wordnetscore</th>\n",
       "      <th>correctN</th>\n",
       "      <th>misspeltN</th>\n",
       "      <th>nounsN</th>\n",
       "      <th>verbsN</th>\n",
       "      <th>adverbsN</th>\n",
       "      <th>adjectivesN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14834</th>\n",
       "      <td>-0.564170</td>\n",
       "      <td>-1.139380</td>\n",
       "      <td>0.043467</td>\n",
       "      <td>-1.033892</td>\n",
       "      <td>0.507557</td>\n",
       "      <td>-0.498194</td>\n",
       "      <td>0.140759</td>\n",
       "      <td>0.499554</td>\n",
       "      <td>0.499554</td>\n",
       "      <td>0.732825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>0.447114</td>\n",
       "      <td>-0.200283</td>\n",
       "      <td>0.332181</td>\n",
       "      <td>0.012597</td>\n",
       "      <td>0.397134</td>\n",
       "      <td>-0.155581</td>\n",
       "      <td>0.144711</td>\n",
       "      <td>0.574577</td>\n",
       "      <td>0.574577</td>\n",
       "      <td>0.580263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>0.251954</td>\n",
       "      <td>0.164922</td>\n",
       "      <td>0.043467</td>\n",
       "      <td>6.291528</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>-1.360350</td>\n",
       "      <td>0.231964</td>\n",
       "      <td>0.228764</td>\n",
       "      <td>0.228764</td>\n",
       "      <td>-0.481705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14837</th>\n",
       "      <td>0.784208</td>\n",
       "      <td>0.530126</td>\n",
       "      <td>0.620895</td>\n",
       "      <td>-0.685062</td>\n",
       "      <td>-1.166780</td>\n",
       "      <td>0.659678</td>\n",
       "      <td>-1.369028</td>\n",
       "      <td>-0.878365</td>\n",
       "      <td>-0.878365</td>\n",
       "      <td>-1.917415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14838</th>\n",
       "      <td>0.127761</td>\n",
       "      <td>0.790986</td>\n",
       "      <td>0.620895</td>\n",
       "      <td>0.710256</td>\n",
       "      <td>1.354531</td>\n",
       "      <td>-1.167522</td>\n",
       "      <td>-0.197375</td>\n",
       "      <td>-0.222881</td>\n",
       "      <td>-0.222881</td>\n",
       "      <td>1.221809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length  lexical_diversity  n_sentences  wordnetscore  correctN  \\\n",
       "essay_id                                                                     \n",
       "14834    -0.564170          -1.139380     0.043467     -1.033892  0.507557   \n",
       "14835     0.447114          -0.200283     0.332181      0.012597  0.397134   \n",
       "14836     0.251954           0.164922     0.043467      6.291528  1.070317   \n",
       "14837     0.784208           0.530126     0.620895     -0.685062 -1.166780   \n",
       "14838     0.127761           0.790986     0.620895      0.710256  1.354531   \n",
       "\n",
       "          misspeltN    nounsN    verbsN  adverbsN  adjectivesN  \n",
       "essay_id                                                        \n",
       "14834     -0.498194  0.140759  0.499554  0.499554     0.732825  \n",
       "14835     -0.155581  0.144711  0.574577  0.574577     0.580263  \n",
       "14836     -1.360350  0.231964  0.228764  0.228764    -0.481705  \n",
       "14837      0.659678 -1.369028 -0.878365 -0.878365    -1.917415  \n",
       "14838     -1.167522 -0.197375 -0.222881 -0.222881     1.221809  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X=(X-X.min())/(X.max()-X.min())\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "col_to_std = ['length','lexical_diversity','n_sentences','wordnetscore','correctN','misspeltN','nounsN','verbsN','adverbsN','adjectivesN']\n",
    "X[col_to_std] = StandardScaler().fit_transform(X[col_to_std])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>wordnetscore</th>\n",
       "      <th>correctN</th>\n",
       "      <th>misspeltN</th>\n",
       "      <th>nounsN</th>\n",
       "      <th>verbsN</th>\n",
       "      <th>adverbsN</th>\n",
       "      <th>adjectivesN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704630</td>\n",
       "      <td>0.784995</td>\n",
       "      <td>0.600038</td>\n",
       "      <td>-0.116262</td>\n",
       "      <td>0.108707</td>\n",
       "      <td>0.022393</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.044306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lexical_diversity</th>\n",
       "      <td>0.704630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505644</td>\n",
       "      <td>0.394189</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>-0.057293</td>\n",
       "      <td>0.044152</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>-0.219457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_sentences</th>\n",
       "      <td>0.784995</td>\n",
       "      <td>0.505644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.466756</td>\n",
       "      <td>-0.167746</td>\n",
       "      <td>0.163243</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.090742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordnetscore</th>\n",
       "      <td>0.600038</td>\n",
       "      <td>0.394189</td>\n",
       "      <td>0.466756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037196</td>\n",
       "      <td>-0.025936</td>\n",
       "      <td>0.021304</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.056399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctN</th>\n",
       "      <td>-0.116262</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>-0.167746</td>\n",
       "      <td>0.037196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.955984</td>\n",
       "      <td>-0.045721</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>-0.075020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misspeltN</th>\n",
       "      <td>0.108707</td>\n",
       "      <td>-0.057293</td>\n",
       "      <td>0.163243</td>\n",
       "      <td>-0.025936</td>\n",
       "      <td>-0.955984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>0.105793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nounsN</th>\n",
       "      <td>0.022393</td>\n",
       "      <td>0.044152</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.021304</td>\n",
       "      <td>-0.045721</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.303579</td>\n",
       "      <td>-0.303579</td>\n",
       "      <td>-0.095574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbsN</th>\n",
       "      <td>0.048700</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>-0.303579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.228514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adverbsN</th>\n",
       "      <td>0.048700</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>-0.303579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.228514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjectivesN</th>\n",
       "      <td>0.044306</td>\n",
       "      <td>-0.219457</td>\n",
       "      <td>0.090742</td>\n",
       "      <td>0.056399</td>\n",
       "      <td>-0.075020</td>\n",
       "      <td>0.105793</td>\n",
       "      <td>-0.095574</td>\n",
       "      <td>0.228514</td>\n",
       "      <td>0.228514</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     length  lexical_diversity  n_sentences  wordnetscore  \\\n",
       "length             1.000000           0.704630     0.784995      0.600038   \n",
       "lexical_diversity  0.704630           1.000000     0.505644      0.394189   \n",
       "n_sentences        0.784995           0.505644     1.000000      0.466756   \n",
       "wordnetscore       0.600038           0.394189     0.466756      1.000000   \n",
       "correctN          -0.116262           0.044281    -0.167746      0.037196   \n",
       "misspeltN          0.108707          -0.057293     0.163243     -0.025936   \n",
       "nounsN             0.022393           0.044152     0.003968      0.021304   \n",
       "verbsN             0.048700          -0.190167     0.095274      0.132317   \n",
       "adverbsN           0.048700          -0.190167     0.095274      0.132317   \n",
       "adjectivesN        0.044306          -0.219457     0.090742      0.056399   \n",
       "\n",
       "                   correctN  misspeltN    nounsN    verbsN  adverbsN  \\\n",
       "length            -0.116262   0.108707  0.022393  0.048700  0.048700   \n",
       "lexical_diversity  0.044281  -0.057293  0.044152 -0.190167 -0.190167   \n",
       "n_sentences       -0.167746   0.163243  0.003968  0.095274  0.095274   \n",
       "wordnetscore       0.037196  -0.025936  0.021304  0.132317  0.132317   \n",
       "correctN           1.000000  -0.955984 -0.045721  0.016804  0.016804   \n",
       "misspeltN         -0.955984   1.000000  0.031232  0.019553  0.019553   \n",
       "nounsN            -0.045721   0.031232  1.000000 -0.303579 -0.303579   \n",
       "verbsN             0.016804   0.019553 -0.303579  1.000000  1.000000   \n",
       "adverbsN           0.016804   0.019553 -0.303579  1.000000  1.000000   \n",
       "adjectivesN       -0.075020   0.105793 -0.095574  0.228514  0.228514   \n",
       "\n",
       "                   adjectivesN  \n",
       "length                0.044306  \n",
       "lexical_diversity    -0.219457  \n",
       "n_sentences           0.090742  \n",
       "wordnetscore          0.056399  \n",
       "correctN             -0.075020  \n",
       "misspeltN             0.105793  \n",
       "nounsN               -0.095574  \n",
       "verbsN                0.228514  \n",
       "adverbsN              0.228514  \n",
       "adjectivesN           1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split X and y into X_\n",
    "n_X_train, n_X_test, n_y_train, n_y_test = train_test_split(normalized_X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(n_X_train, n_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.69293551, -0.40793348,  0.44695263,  2.51322157,  3.3054924 ,\n",
       "        2.57487967,  1.58292482,  0.34557344,  0.34557344,  1.23970997])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5541919471699364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,accuracy_score\n",
    "print(regression_model.score(n_X_test, n_y_test))\n",
    "y_pred = regression_model.predict(n_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[  1   5   2   1   0]\n",
      " [  1  10  21   9   0]\n",
      " [  0   4  43  32   2]\n",
      " [  0   0  13 136  20]\n",
      " [  0   0   0  28  32]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.11      0.18         9\n",
      "           1       0.53      0.24      0.33        41\n",
      "           2       0.54      0.53      0.54        81\n",
      "           3       0.66      0.80      0.73       169\n",
      "           4       0.59      0.53      0.56        60\n",
      "\n",
      "    accuracy                           0.62       360\n",
      "   macro avg       0.56      0.44      0.47       360\n",
      "weighted avg       0.60      0.62      0.60       360\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_random = RandomForestClassifier(criterion='entropy', \n",
    "                            n_estimators=1000, \n",
    "                            min_samples_leaf=4, \n",
    "                            min_samples_split=2, \n",
    "                            max_features='auto',\n",
    "                            max_depth=None,\n",
    "                            bootstrap=True,\n",
    "                            random_state=2)\n",
    "\n",
    "# Fit rf to the training set    \n",
    "rf_random.fit(n_X_train, n_y_train)\n",
    "\n",
    "# predict\n",
    "n_y_pred = rf_random.predict(n_X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(n_y_test, n_y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(n_y_test, n_y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    " \n",
    "importances = pd.Series(data=rf_random.feature_importances_, index= n_X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
